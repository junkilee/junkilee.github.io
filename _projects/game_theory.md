---
layout: page
title: game theory
description: Stackelerg punishment and bully-proofing autonomous vehicles
img: assets/img/projects/game_theory.jpg
importance: 4
category: brown
---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/projects/game_theory.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

Mutually beneficial behavior in repeated games can be enforced via the threat of punishment, as enshrined in game theory’s wellknown “folk theorem.” There is a cost, however, to a player for generating these disincentives. In this work, we seek to minimize this cost by computing a “Stackelberg punishment,” in which the player selects a behavior that sufficiently punishes the other player while maximizing its own score under the assumption that the other player will adopt a best response. This idea generalizes the concept of a Stackelberg equilibrium. Known efficient algorithms for computing a Stackelberg equilibrium can be adapted to efficiently produce a Stackelberg punishment. We demonstrate an application of this idea in an experiment involving a virtual autonomous vehicle and human participants. We find that a self-driving car with a Stackelberg punishment policy discourages human drivers from bullying in a driving scenario requiring social negotiation.

M. Cooper, J. K. Lee, J. Beck, J. D. Fishman, M. Gillett, Z. Papakipos, A. Zhang, J. Ramos, A. Shah, and M. L. Littman (2019), <b>“Stackelberg punishment and bully-proofing autonomous vehicles,”</b> in 2019 Interactional Conference on Social robotics, 368-377. 